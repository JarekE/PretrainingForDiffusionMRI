{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example\n",
    "## Pretraining for Diffusion MRI\n",
    "\n",
    "In this example, the functionality of the code is demonstrated by fine-tuning a pretrained network for segmentation\n",
    "of the dMRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from ExperimentModule import ExperimentModule\n",
    "import ExperimentDataloader\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Firstly, we load our model. To do this, we access the appropriate pretrained network from the \"PretrainedModels\" folder\n",
    "and initialise it as a new network. Here we decide on a network that is to perform a segmentation and uses a classic\n",
    "autoencoding-transformed network without artificial distortions for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ExperimentModule(learning_mode='segmentation', pretrained='pre', distortions='nodist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we load the data. These are automatically divided into a test-, training- and validation-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = ExperimentDataloader.DataModule(learning_mode='segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To carry out the training we use PyTorch-Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | unet      | UNet3d   | 2.1 M \n",
      "1 | out_block | Conv3d   | 68    \n",
      "2 | loss      | L1Loss   | 0     \n",
      "3 | metric    | F1       | 0     \n",
      "4 | metric2   | Accuracy | 0     \n",
      "---------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.271     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 0it [00:00, ?it/s]\n",
      " Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/scratch/ecke/PretrainingForDiffusionMRI/ExperimentDataset.py:107: RuntimeWarning: invalid value encountered in true_divide\n",
      "  edw = np.divide(dwi, meanb0)\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/work/scratch/ecke/miniconda2/envs/env3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation Loss: tensor(0.5032, device='cuda:0')\n",
      "\n",
      "\n",
      "                                                                      \n",
      " Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n",
      "/work/scratch/ecke/miniconda2/envs/env3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/work/scratch/ecke/miniconda2/envs/env3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:323: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:00,  1.27it/s, loss=0.503, v_num=0]\n",
      "\n",
      "Validation Loss: tensor(0.4382, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 1:  50%|█████     | 1/2 [00:00<00:00,  3.37it/s, loss=0.471, v_num=0]   \n",
      "\n",
      "Validation Loss: tensor(0.3793, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 2:  50%|█████     | 1/2 [00:00<00:00,  3.29it/s, loss=0.44, v_num=0]    \n",
      "\n",
      "Validation Loss: tensor(0.3539, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 3:  50%|█████     | 1/2 [00:00<00:00,  3.28it/s, loss=0.419, v_num=0]  \n",
      "\n",
      "Validation Loss: tensor(0.3344, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 4:  50%|█████     | 1/2 [00:00<00:00,  3.32it/s, loss=0.402, v_num=0]   \n",
      "\n",
      "Validation Loss: tensor(0.3197, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 5:  50%|█████     | 1/2 [00:00<00:00,  3.31it/s, loss=0.388, v_num=0]   \n",
      "\n",
      "Validation Loss: tensor(0.3110, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 6:  50%|█████     | 1/2 [00:00<00:00,  3.04it/s, loss=0.377, v_num=0]   \n",
      "\n",
      "Validation Loss: tensor(0.3033, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 7:  50%|█████     | 1/2 [00:00<00:00,  3.21it/s, loss=0.368, v_num=0]   \n",
      "\n",
      "Validation Loss: tensor(0.2960, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 8:  50%|█████     | 1/2 [00:00<00:00,  3.31it/s, loss=0.36, v_num=0]    \n",
      "\n",
      "Validation Loss: tensor(0.2919, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 9:  50%|█████     | 1/2 [00:00<00:00,  3.29it/s, loss=0.353, v_num=0]  \n",
      "\n",
      "Validation Loss: tensor(0.2903, device='cuda:0')\n",
      "\n",
      "\n",
      "Epoch 9: 100%|██████████| 2/2 [00:03<00:00,  1.03s/it, loss=0.353, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_epochs=10,\n",
    "                     deterministic=True,\n",
    "                     log_every_n_steps=10,\n",
    "                     resume_from_checkpoint=0)\n",
    "\n",
    "trainer.fit(model, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, the network can be tested. The results are written here in an Excel file, which is created in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/scratch/ecke/miniconda2/envs/env3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:679: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "/work/scratch/ecke/miniconda2/envs/env3.7/lib/python3.7/site-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n",
      "/work/scratch/ecke/miniconda2/envs/env3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'AccuracyORMAE': 0.757314920425415,\n",
      " 'AccuracyORMAE_epoch': 0.757314920425415,\n",
      " 'f1ORMSE': 0.01439349539577961,\n",
      " 'f1ORMSE_epoch': 0.01439349539577961,\n",
      " 'test_loss': 0.2902667820453644,\n",
      " 'test_loss_epoch': 0.2902667820453644}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2902667820453644,\n",
       "  'test_loss_epoch': 0.2902667820453644,\n",
       "  'f1ORMSE': 0.01439349539577961,\n",
       "  'f1ORMSE_epoch': 0.01439349539577961,\n",
       "  'AccuracyORMAE': 0.757314920425415,\n",
       "  'AccuracyORMAE_epoch': 0.757314920425415}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(ckpt_path='best', test_dataloaders=dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
